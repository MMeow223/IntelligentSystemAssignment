{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgnjGr9TjIVi"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision  # Required for YOLOv5\n",
        "!pip install opencv-python  # Required for image processing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCOH83YjHTBG",
        "outputId": "2098adc3-e24b-4f14-9fe0-07c6d62e7272"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # Clone the YOLOv5 repository\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt  # Install YOLOv5 dependencies\n"
      ],
      "metadata": {
        "id": "7qn7CW5yKSlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models import load_state_dict_from_url\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5s.pt', force_reload=True)  # YOLOv5 model\n",
        "model.eval()  # Set the model to evaluation mode\n"
      ],
      "metadata": {
        "id": "aNObyKbnKTXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "# Define the path to the CNN folder in your Google Drive\n",
        "cnn_folder_path = '/content/drive/MyDrive/CNN'\n",
        "\n",
        "# Define the directory paths for the normal and dark folders\n",
        "normal_folder_path = os.path.join(cnn_folder_path, 'normal')\n",
        "dark_folder_path = os.path.join(cnn_folder_path, 'dark')\n",
        "\n",
        "# Define the image directories\n",
        "image_dirs = {\n",
        "    'normal_train': os.path.join(normal_folder_path, 'train'),\n",
        "    'dark_train': os.path.join(dark_folder_path, 'train')\n",
        "}\n",
        "\n",
        "# Detect humans with YOLOv5 and crop images\n",
        "for image_dir_key, image_dir_path in image_dirs.items():\n",
        "    print('Processing images in:', image_dir_key)\n",
        "    \n",
        "    for class_name in ['sit', 'walk', 'fall']:\n",
        "        class_dir = os.path.join(image_dir_path, class_name)\n",
        "\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image_name)\n",
        "\n",
        "            # Load the image\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Detect objects using YOLOv5\n",
        "            results = model(image)\n",
        "\n",
        "            # Extract bounding boxes and crop images\n",
        "            for detection in results.pandas().xyxy[0].itertuples():\n",
        "                xmin, ymin, xmax, ymax, _, _, _, _ = detection[1:]\n",
        "                cropped_image = image[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "\n",
        "                # Save the cropped image or perform further processing\n",
        "                cropped_image_path = os.path.join(image_dir_path, 'cropped', class_name, image_name)\n",
        "                os.makedirs(os.path.dirname(cropped_image_path), exist_ok=True)\n",
        "                cv2.imwrite(cropped_image_path, cropped_image)\n"
      ],
      "metadata": {
        "id": "g1yXMqO8Kf2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_dataset(dataset_path):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for class_name in os.listdir(dataset_path):\n",
        "        class_dir = os.path.join(dataset_path, class_name)\n",
        "        \n",
        "        for image_name in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image_name)\n",
        "            \n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale if needed\n",
        "            \n",
        "            X.append(image)\n",
        "            y.append(class_name)\n",
        "    \n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "# Define the path to your cropped images dataset\n",
        "dataset_path = '/content/drive/MyDrive/CNN/normal_train/cropped'\n",
        "\n",
        "# Load the dataset\n",
        "X, y = load_dataset(dataset_path)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Q4j2ptMXKhv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import hog\n",
        "\n",
        "def extract_hog_features(images):\n",
        "    features = []\n",
        "\n",
        "    for image in images:\n",
        "        feature_vector = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)\n",
        "        features.append(feature_vector)\n",
        "    \n",
        "    return np.array(features)\n",
        "\n",
        "# Extract HOG features from the training and validation sets\n",
        "X_train_hog = extract_hog_features(X_train)\n",
        "X_val_hog = extract_hog_features(X_val)\n"
      ],
      "metadata": {
        "id": "aGUM4ObAKinp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create and train the SVM classifier\n",
        "hog_classifier = SVC()\n",
        "hog_classifier.fit(X_train_hog, y_train)\n"
      ],
      "metadata": {
        "id": "Xp7SjMG9KqkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = hog_classifier.predict(X_val_hog)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print('Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "CLddRDdcKsgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to save the HOG classifier model\n",
        "hog_model_path = '/content/drive/MyDrive/CNN/hog_classifier.pkl'\n",
        "\n",
        "# Save the HOG classifier model\n",
        "import joblib\n",
        "joblib.dump(hog_classifier, hog_model_path)\n"
      ],
      "metadata": {
        "id": "vdhJy91pKuf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import joblib\n",
        "\n",
        "# Load the trained HOG classifier model\n",
        "hog_model_path = '/content/drive/MyDrive/CNN/hog_classifier.pkl'\n",
        "hog_classifier = joblib.load(hog_model_path)\n"
      ],
      "metadata": {
        "id": "R23DU2SaKwyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect humans with YOLOv5 and feed cropped images to HOG classifier\n",
        "for detection in results.pandas().xyxy[0].itertuples():\n",
        "    xmin, ymin, xmax, ymax, _, _, _, _ = detection[1:]\n",
        "    cropped_image = image[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "\n",
        "    # Resize the cropped image to match the input size of the HOG classifier\n",
        "    resized_image = cv2.resize(cropped_image, (64, 128))  # Adjust the size as needed\n",
        "\n",
        "    # Convert the resized image to grayscale if needed\n",
        "    resized_image_gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Extract HOG features from the resized image\n",
        "    hog_features = hog(resized_image_gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)\n",
        "\n",
        "    # Reshape the feature vector to match the expected input shape of the HOG classifier\n",
        "    hog_features = hog_features.reshape(1, -1)\n",
        "\n",
        "    # Make prediction using the HOG classifier\n",
        "    action_prediction = hog_classifier.predict(hog_features)\n",
        "\n",
        "    # Print the predicted action\n",
        "    print(\"Action Prediction:\", action_prediction)\n"
      ],
      "metadata": {
        "id": "tqebmpuqK0Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def detect_and_classify(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Detect objects using YOLOv5\n",
        "    results = model(image)\n",
        "\n",
        "    # Process each detection\n",
        "    for detection in results.pandas().xyxy[0].itertuples():\n",
        "        xmin, ymin, xmax, ymax, _, _, _, _ = detection[1:]\n",
        "        cropped_image = image[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "\n",
        "        # Resize the cropped image to match the input size of the HOG classifier\n",
        "        resized_image = cv2.resize(cropped_image, (64, 128))  # Adjust the size as needed\n",
        "\n",
        "        # Convert the resized image to grayscale if needed\n",
        "        resized_image_gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Extract HOG features from the resized image\n",
        "        hog_features = hog(resized_image_gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)\n",
        "\n",
        "        # Reshape the feature vector to match the expected input shape of the HOG classifier\n",
        "        hog_features = hog_features.reshape(1, -1)\n",
        "\n",
        "        # Make prediction using the HOG classifier\n",
        "        action_prediction = hog_classifier.predict(hog_features)\n",
        "\n",
        "        # Print the predicted action\n",
        "        print(\"Action Prediction:\", action_prediction)\n",
        "\n",
        "        # Display the image with bounding box and action prediction\n",
        "        cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
        "        cv2.putText(image, action_prediction[0], (int(xmin), int(ymin) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    # Convert BGR to RGB for plotting\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Plot the image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Define the paths to the test directories\n",
        "normal_test_dir = '/content/drive/MyDrive/CNN/normal/test'\n",
        "dark_test_dir = '/content/drive/MyDrive/CNN/dark/test'\n",
        "\n",
        "# Test images in the normal test directory\n",
        "print('Testing images in normal test directory:')\n",
        "for image_name in os.listdir(normal_test_dir):\n",
        "    image_path = os.path.join(normal_test_dir, image_name)\n",
        "    print('Image:', image_name)\n",
        "    detect_and_classify(image_path)\n",
        "\n",
        "# Test images in the dark test directory\n",
        "print('Testing images in dark test directory:')\n",
        "for image_name in os.listdir(dark_test_dir):\n",
        "    image_path = os.path.join(dark_test_dir, image_name)\n",
        "    print('Image:', image_name)\n",
        "    detect_and_classify(image_path)\n"
      ],
      "metadata": {
        "id": "btEbwZATLXeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, confusion_matrix, f1_score, roc_curve, roc_auc_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Define a function to calculate precision-recall curve and plot it\n",
        "def plot_precision_recall(y_true, y_pred_prob):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Define a function to calculate and plot the confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Define a function to calculate F1-confidence curve and plot it\n",
        "def plot_f1_confidence_curve(y_true, y_pred_prob):\n",
        "    thresholds = np.arange(0, 1.05, 0.05)\n",
        "    f1_scores = []\n",
        "    confidences = []\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_pred_prob >= threshold).astype(int)\n",
        "        f1_scores.append(f1_score(y_true, y_pred))\n",
        "        confidences.append(np.mean(y_pred_prob))\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(confidences, f1_scores)\n",
        "    plt.xlabel('Confidence')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.title('F1-Confidence Curve')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Define a function to calculate ROC curve and plot it\n",
        "def plot_roc_curve(y_true, y_pred_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
        "    auc = roc_auc_score(y_true, y_pred_prob)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve (AUC = {:.3f})'.format(auc))\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Define the paths to the test directories\n",
        "normal_test_dir = '/content/drive/MyDrive/CNN/normal/test'\n",
        "dark_test_dir = '/content/drive/MyDrive/CNN/dark/test'\n",
        "\n",
        "# Initialize lists to store true labels and predicted probabilities\n",
        "y_true = []\n",
        "y_pred_prob = []\n",
        "\n",
        "# Test images in the normal test directory\n",
        "print('Testing images in normal test directory:')\n",
        "for image_name in os.listdir(normal_test_dir):\n",
        "    image_path = os.path.join(normal_test_dir, image_name)\n",
        "    print('Image:', image_name)\n",
        "    detect_and_classify(image_path)  # Modify this line to append true labels and predicted probabilities\n",
        "\n",
        "# Test images in the dark test directory\n",
        "print('Testing images in dark test directory:')\n",
        "for image_name in os.listdir(dark_test_dir):\n",
        "    image_path = os.path.join(dark_test_dir, image_name)\n",
        "    print('Image:', image_name)\n",
        "    detect_and_classify(image_path)  # Modify this line to append true labels and predicted probabilities\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred_prob = np.array(y_pred_prob)\n",
        "\n",
        "# Calculate and plot precision-recall curve\n",
        "plot_precision_recall(y_true, y_pred_prob)\n",
        "\n",
        "# Calculate and plot confusion matrix\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)  # Adjust the threshold as needed\n",
        "plot_confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Calculate and plot F1-confidence curve\n",
        "plot_f1_confidence_curve(y_true, y_pred_prob)\n",
        "\n",
        "# Calculate and plot ROC curve\n",
        "plot_roc_curve(y_true, y_pred_prob)"
      ],
      "metadata": {
        "id": "6ncvfXh_L7XZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}